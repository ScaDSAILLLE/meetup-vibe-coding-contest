# Goose Desktop Installation & Setup Guide**

**Goose Desktop** ist eine lokale, sichere und isolierte Entwicklungsumgebung fÃ¼r KI-gestÃ¼tzte Workflows.
Es kombiniert:

* LLM-Anbindung (OpenAI, Anthropic, OpenAI-kompatibel)
* isolierte Sandboxes fÃ¼r CodeausfÃ¼hrung
* Chat + Tools + Agenten

Dieser Guide zeigt nur das **NÃ¶tigste fÃ¼r Installation, Setup und erste Tests**.
Vertiefende Features werden unten verlinkt.

---

# **1. Installation**

Die offiziellen Installationen stehen hier:
âž¡ï¸ **[https://block.github.io/goose/docs/getting-started/installation/](https://block.github.io/goose/docs/getting-started/installation/)**

### **1.1 Download Goose Desktop**

Lade die passende Version herunter:

* **macOS (.dmg)**
* **Windows (.exe)**
* **Linux (.AppImage)**

Downloadseite (offizielle Docs):
[https://block.github.io/goose/docs/getting-started/installation/](https://block.github.io/goose/docs/getting-started/installation/)

### **1.2 Installation je OS**

**macOS**

1. `.dmg` Ã¶ffnen
2. Goose in â€žApplicationsâ€œ ziehen
3. Falls macOS fragt: *â€žApp erlaubenâ€œ* bestÃ¤tigen

**Windows**

1. `.exe` starten
2. Installer durchklicken
3. Goose Desktop starten

**Linux**

```bash
chmod +x GooseDesktop*.AppImage
./GooseDesktop*.AppImage
```

Nach der Installation Goose Ã¶ffnen â†’ du siehst links *Chat*, *Agents*, *Files*, *Run*, *Settings*.

---

# **2. LLM-Provider konfigurieren (nur das NÃ¶tigste)**

Goose unterstÃ¼tzt standardmÃ¤ÃŸig drei Provider:

* **OpenAI**
* **Anthropic**
* **OpenAI-compatible APIs**
  (z. B. Ollama, LM Studio, lokale KI-Cluster wie KIARA)

Die Provider-Konfiguration findest du hier:
âž¡ï¸ **[https://block.github.io/goose/docs/getting-started/providers/](https://block.github.io/goose/docs/getting-started/providers/)**

In der App unter:
**Settings â†’ Providers**

---

## **2.1 OpenAI konfigurieren**

1. API-Key eingeben
   (Contest-Key aus der Cloud oder selbst erzeugt Ã¼ber [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys))

2. In Goose:
   **Settings â†’ Providers â†’ OpenAI**

Eintragen:

| Feld     | Beispiel                                   |
| -------- | ------------------------------------------ |
| API Base | `https://api.openai.com/v1`                |
| API Key  | `sk-...`                                   |
| Model    | z. B. `gpt-4.1`, `gpt-4.1-mini`, `o3-mini` |

**Verbindung mit â€žTest Connectionâ€œ prÃ¼fen.**

---

## **2.2 Anthropic (Claude) konfigurieren**

1. API-Key eintragen
   (Contest-Key oder: [https://console.anthropic.com/account/keys](https://console.anthropic.com/account/keys))

2. In Goose:
   **Settings â†’ Providers â†’ Anthropic**

Eintragen:

| Feld     | Beispiel                                                       |
| -------- | -------------------------------------------------------------- |
| API Base | `https://api.anthropic.com/v1/messages` *(Standard laut Docs)* |
| API Key  | `sk-ant-...`                                                   |
| Model    | `claude-3-sonnet`, `claude-3-opus`, `claude-3-haiku`           |

**â€žTest Connectionâ€œ klicken.**

---

## **2.3 OpenAI-compatible Provider (z. B. KIARA, Ollama, LM Studio)**

Goose unterstÃ¼tzt jede API, die das **OpenAI-v1-Format** spricht.

Doku:
âž¡ï¸ [https://block.github.io/goose/docs/getting-started/providers/#openai-compatible](https://block.github.io/goose/docs/getting-started/providers/#openai-compatible)

---

### **Beispiel 1: KIARA Cluster URZ (vLLM)**

| Feld     | Eintrag                                       |
| -------- | --------------------------------------------- |
| API Base | `https://kiara.sc.uni-leipzig.de/api`         |
| API Key  | Contest-Cloud                                 |
| Model    | z. B. `vllm-meta-llama-llama3-3-70b-instruct` |

â€žTest Connectionâ€œ â†’ sollte sofort grÃ¼n werden.

---

### **Beispiel 2: Ollama (lokal)**

1. Installieren: [https://ollama.com](https://ollama.com)
2. Modell verfÃ¼gbar machen:

   ```bash
   ollama run llama3
   ```
3. Goose:

| Feld     | Eintrag                     |
| -------- | --------------------------- |
| API Base | `http://localhost:11434/v1` |
| API Key  | beliebig (â€žollamaâ€œ)         |
| Model    | `llama3`                    |

---

### **Beispiel 3: LM Studio**

1. LM Studio starten
2. â€žOpenAI-compatible API Serverâ€œ aktivieren
3. Goose:

| Feld     | Eintrag                          |
| -------- | -------------------------------- |
| API Base | z. B. `http://localhost:1234/v1` |
| Model    | Auswahl aus LM Studio            |

---

# **3. Erste Tests**

Analog zu deiner Void-README â€“ minimal, aber funktional.

---

## **Test 1: Chat**

1. Links â€žChatâ€œ Ã¶ffnen
2. Provider auswÃ¤hlen (OpenAI / Anthropic / KIARA / lokal)
3. Nachricht senden:

> â€žHallo Goose! Funktionierst du?â€œ

Wenn eine Antwort kommt â†’ Modell funktioniert.

---

## **Test 2: Code-AusfÃ¼hrung**

1. Links â€žRunâ€œ oder â€žSandboxâ€œ Ã¶ffnen
2. Code eingeben:

```python
print("Hello from Goose Desktop!")
```

3. â€žRunâ€œ klicken

â†’ Ausgabe erscheint im unteren Fenster.

---

## **Test 3: Einfacher Agent-Workflow**

1. Links â€žAgentsâ€œ Ã¶ffnen
2. â€žDefault Agentâ€œ oder eigenen erstellen
3. Prompt:

> â€žErstelle drei Projektideen fÃ¼r ein Micro-SaaS.â€œ

Wenn Goose mehrere Schritte ausfÃ¼hrt â†’ Agenten funktionieren.

---

# **4. Troubleshooting**

### **â€ž401 Unauthorizedâ€œ**

â†’ Falscher API-Key
â†’ Falscher Endpoint (Achtung: muss `/v1` haben)

### **â€žModel not foundâ€œ**

â†’ Modellname exakt prÃ¼fen
â†’ Bei Ollama Modell vorher â€žziehenâ€œ

### **Keine Antwort**

â†’ Netzwerkblocker / Firewall
â†’ LM Studio/Ollama/vLLM nicht gestartet

---

# **5. WeiterfÃ¼hrende Features (fÃ¼r Fortgeschrittene)**

Goose bietet viele leistungsstarke Funktionen, die Ã¼ber den Grund-Setup hinausgehen:

ðŸ”— **Guides:**
[https://block.github.io/goose/docs/category/guides](https://block.github.io/goose/docs/category/guides)

Empfohlen fÃ¼r Contest-Teilnehmende:

* **Sessions** â€“ persistente Arbeitskontexte
* **Recipes** â€“ wiederverwendbare automatisierte AblÃ¤ufe
* **Scheduler** â€“ zeit- oder eventbasierte Agent-Runs
* **Tools** â€“ Dateisystem, Python, Bash, Browser, Custom Tools
* **Agents** â€“ komplexe Multi-Step Reasoning Workflows
* **Sandboxes** â€“ isolierte sichere Coding-Umgebungen

Diese Features erlauben echtes **Vibe Coding mit autonomen Agenten**.
