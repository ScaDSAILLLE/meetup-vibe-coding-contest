# Goose Desktop Installation & Setup Guide**

**Goose Desktop** ist eine lokale, KI-Agent(en) basierte Entwicklungsumgebung fÃ¼r KI-gestÃ¼tzte Workflows und Automation.
Es kombiniert:

* modellagnostische LLM-Anbindung (OpenAI, Anthropic, OpenAI-kompatibel, etc.)
* bietet von Code-VorschlÃ¤gen Ã¼ber Code schreiben und ausfÃ¼hren, Fehler beheben bis hin zum koordinieren von Workflows sowie interagieren externer APIs zahlreiche nÃ¼tzliche Features 
* Chat + Tools (MCP) + Agenten 

Dieser Guide fÃ¼hrt durch: \
1. Installation 
2. Konfiguration von OpenAI, Anthropic & OpenAI-kompatiblen Endpoints
3. Erste Funktionstests (Chat, Quick-Edit, Model-Check)

---

# **1. Installation**

### **Offizielle Downloads**

Die offiziellen Installationen stehen hier:
âž¡ï¸ **[https://block.github.io/goose/docs/getting-started/installation/](https://block.github.io/goose/docs/getting-started/installation/)**

Bitte die nÃ¶tige OS-Plattform wÃ¤hlen und klassich den Installationsprozess durchspielen. \
Weitere Informationen dazu findest du [hier](https://block.github.io/goose/docs/quickstart).

---

# **2. LLM-Provider konfigurieren**

Goose unterstÃ¼tzt zahlreiche Provider von den nahmhaften Ã¼ber Anbieter von Proxys (z.B. OpenRouter, die alle proprietÃ¤ren Modelle hinter ihrer API anbieten) bis hin zu lokal anzubindenden LLM-Backends (Ollama, LMStudio). Wir nutzen heute folgende: 

* **OpenAI**
* **Anthropic**
* **OpenAI-compatible APIs**
  (KIARA Cluster URZ, es gehten aber auch z. B. Ollama, LM Studio)

Die Provider-Konfiguration findest du hier:
âž¡ï¸ **[https://block.github.io/goose/docs/getting-started/providers/](https://block.github.io/goose/docs/getting-started/providers/)**

In der App unter:
**Settings â†’ *Models*-Tab â†’ *Configure Providers* klicken**

---

## **2.1 OpenAI konfigurieren**

1. API-Key eintragen\
Findet ihr fÃ¼r den Vibe-Coding-Contest Ã¼ber den in den Slides geteilten Cloud-Link.
Alternativ API-Key erstellen:
   [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)

2. In Goose:
   **Settings â†’ *Models*-Tab â†’ *Configure Providers* klicken â†’ *OpenAI* auswÃ¤hlen â†’ API-Key eintragen**

3. Weitere EintrÃ¤ge:
   * API-Host `https://api.openai.com` und 
   * Base Path `v1/chat/completions` sollten beide bereits eingetragen sein.

VerfÃ¼gbare Modelle werden dann automatisch erfragt und fÃ¼r den Chat angeboten. 

---

## **2.2 Anthropic (Claude) konfigurieren**

1. API-Key eintragen\
Findet ihr fÃ¼r den Vibe-Coding-Contest Ã¼ber den in den Slides geteilten Cloud-Link.
Alternativ API-Key erstellen:
   [https://console.anthropic.com/account/keys](https://console.anthropic.com/account/keys)

2. In Goose:
   **Settings â†’ *Models*-Tab â†’ *Configure Providers* klicken â†’ *OpenAI* auswÃ¤hlen â†’ API-Key eintragen**

3. Weitere EintrÃ¤ge:
   * API-Host `https://api.anthropic.com` sollte bereits eingetragen sein.

---

## **2.3 OpenAI-compatible Provider (z. B. KIARA, Ollama, LM Studio)**

Goose unterstÃ¼tzt jede API, die das **OpenAI-v1-Format** spricht.

Doku:
âž¡ï¸ [https://block.github.io/goose/docs/getting-started/providers/#openai-compatible](https://block.github.io/goose/docs/getting-started/providers/#openai-compatible)

---

### **KIARA Cluster URZ (vLLM)**

1. API-Key eintragen\
Findet ihr fÃ¼r den Vibe-Coding-Contest Ã¼ber den in den Slides geteilten Cloud-Link.

2. In Goose:
   **Settings â†’ *Models*-Tab â†’ *Configure Providers* klicken â†’ *Add custom provider* auswÃ¤hlen**

3. Weitere EintrÃ¤ge:
   * Provider Type: *OpenAI Compatible* auswÃ¤hlen
   * Display Name: KIARA
   * API-URL `https://kiara.sc.uni-leipzig.de/api`
   * API-KEY eintragen
   * Modell(e) eintragen (komma-separiert, falls mehrere eingetragen werden sollen); wir nutzen heute: `vllm-meta-llama-llama-3-3-70b-instruct`
   * *Create Provider* klicken

---

# **3. Erste Tests**

## **Test: Chat / LLM-Provider erreichbar**

1. Links â€žChatâ€œ Ã¶ffnen
2. Falls  nÃ¶tig unten bei der Texteingabe vom Chat Provider auswÃ¤hlen (OpenAI / Anthropic / KIARA / lokal) oder unter **Settings â†’ *Models*-Tab** (s. oben)
3. Nachricht senden:

> â€žHallo Goose! Funktionierst du?â€œ

Wenn eine Antwort kommt â†’ Modell funktioniert.

---

# **4. WeiterfÃ¼hrende Features (fÃ¼r Fortgeschrittene)**

Goose bietet viele leistungsstarke Funktionen, die Ã¼ber den Grund-Setup hinausgehen:

ðŸ”— **Guides:**
[https://block.github.io/goose/docs/category/guides](https://block.github.io/goose/docs/category/guides)

Empfohlen fÃ¼r Contest-Teilnehmende:

* **Multi-Sessions** â€“ persistente Arbeitskontexte Ã¼ber diverse Chats (Stichwort *Sub-Agents*)
* **Recipes** â€“ wiederverwendbare automatisierte AblÃ¤ufe
* **Scheduler** â€“ zeit- oder eventbasierte Agent-Runs
* **Tools** â€“ Dateisystem, Python, Bash, Browser, Custom Tools
* **Extensions** â€“ diverse Integrationen / Anbindungen via MCP (Model Context Protocol)

Diese Features erlauben echtes **Vibe Coding mit autonomen Agenten**.

# **5. Troubleshooting**

### **â€ž401 Unauthorizedâ€œ**

â†’ Falscher API-Key
â†’ Falscher Endpoint 

### **â€žModel not foundâ€œ**

â†’ Modellname exakt prÃ¼fen

### **Keine Antwort**

â†’ Netzwerkblocker / Firewall
â†’ ggf. timeout?
â†’ LMStudio/Ollama/vLLM nicht gestartet

---
